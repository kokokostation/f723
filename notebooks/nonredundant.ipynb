{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "import multiprocessing_on_dill as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from cityhash import CityHash64\n",
    "from itertools import groupby\n",
    "\n",
    "from f723.tools.urs.extraction import assemble_chains, get_sec_struct_model\n",
    "from f723.tools.dataset.entities import NucleotideFeatures, PairFeatures, PairMeta, PairData, make_pair, Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/home/mikhail/bioinformatics/data/dataset_all_60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = os.path.join(DATASET_DIR, 'features.npy')\n",
    "TARGET_PATH = os.path.join(DATASET_DIR, 'target.npy')\n",
    "GROUPS_PATH = os.path.join(DATASET_DIR, 'groups.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_SHAPE = (6830702, 465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features():\n",
    "    features = np.memmap(FEATURES_PATH, shape=FEATURES_SHAPE)\n",
    "    target = np.load(TARGET_PATH)\n",
    "    pdb_ids = np.load(GROUPS_PATH)\n",
    "    \n",
    "    return features, target, pdb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, pdb_ids = load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(index):\n",
    "    with open(os.path.join(DATASET_DIR, 'batch_{}'.format(index)), 'rb') as infile:\n",
    "        return dill.load(infile)\n",
    "    \n",
    "\n",
    "def get_data():\n",
    "    return chain.from_iterable((get_batch(i) for i in tqdm(range(30))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:24<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "chain_ids = ['{}.cif1_{}'.format(sample.meta.pdb_id, sample.meta.pair.nt_left.chain_id) \n",
    "             for sample in get_data()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mikhail/bioinformatics/data/nonredundant.txt', 'r') as infile:\n",
    "    nonredundant_chain_ids = infile.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonredundant_mask = np.repeat([chain_id in nonredundant_chain_ids for chain_id in chain_ids], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1494852"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonredundant_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nonredundant / all = 1494852 / 6807514 -- всего в 4 раза меньше, не так ужи плохо "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (target != 0) & nonredundant_mask \n",
    "\n",
    "features = features[mask]\n",
    "target = target[mask]\n",
    "pdb_ids = pdb_ids[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive rate: 0.0028090995111181203, test positive rate: 0.002196188948895125\n",
      "(array([0.84126984, 0.99788173]), array([0.03557047, 0.99998523]), array([0.06825499, 0.99893237]), array([  1490, 676958]))\n",
      "Train positive rate: 0.0026193717645793075, test positive rate: 0.0023650688124221514\n",
      "(array([0.7755102 , 0.99777971]), array([0.06138934, 0.99995787]), array([0.11377246, 0.9988676 ]), array([  1238, 522214]))\n",
      "Train positive rate: 0.0024644285982737524, test positive rate: 0.003484320557491289\n",
      "(array([1.        , 0.99669244]), array([0.0508982, 1.       ]), array([0.0968661 , 0.99834348]), array([  334, 95524]))\n",
      "Train positive rate: 0.002454373188088759, test positive rate: 0.003630672926447574\n",
      "(array([1.        , 0.99652528]), array([0.04310345, 1.        ]), array([0.08264463, 0.99825962]), array([  348, 95502]))\n",
      "Train positive rate: 0.0024468860683922594, test positive rate: 0.0037310339109526574\n",
      "(array([1.        , 0.99659949]), array([0.08888889, 1.        ]), array([0.16326531, 0.99829685]), array([  360, 96128]))\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "group_kfold.get_n_splits(features, target, pdb_ids)\n",
    "\n",
    "feature_importances = []\n",
    "target_pred = np.zeros_like(target)\n",
    "pred_proba = np.zeros_like(target, dtype=np.float32)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(features, target, pdb_ids):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    print('Train positive rate: {}, test positive rate: {}'.format(\n",
    "        np.mean(y_train == 1), np.mean(y_test == 1)))\n",
    "    \n",
    "    model = RandomForestClassifier(class_weight='balanced', n_estimators=100, n_jobs=8)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    feature_importances.append(model.feature_importances_)\n",
    "    target_pred[test_index] = y_pred\n",
    "    pred_proba[test_index] = model.predict_proba(X_test)[:, 0]\n",
    "    \n",
    "    print(precision_recall_fscore_support(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
